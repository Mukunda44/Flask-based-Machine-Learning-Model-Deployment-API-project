# Flask-based ML Model Deployment API

## Overview
This project demonstrates how to deploy a **Machine Learning model** as a **REST API** using Flask. It loads a pre-trained **Logistic Regression model** trained on the **Iris dataset**, validates incoming requests, and returns predictions through clean JSON responses. The project is designed to meet real-world API development standards, including: config-driven model loading, input validation and structured error handling, authentication and CORS, logging and testing with Flask test client, and containerization with Docker.

## ğŸ“ Project Structure
flask-ml-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py          # Flask app factory (CORS, routes, model load)
â”‚   â”œâ”€â”€ main.py              # Entry point (python -m app)
â”‚   â”œâ”€â”€ auth.py              # API key authentication decorator
â”‚   â”œâ”€â”€ config.py            # Loads settings.yaml config
â”‚   â”œâ”€â”€ errors.py            # Global error handlers + structured logging
â”‚   â”œâ”€â”€ model.py             # IrisModel: load + predict methods
â”‚   â”œâ”€â”€ routes.py            # /health, /predict, /batch_predict endpoints
â”‚   â””â”€â”€ schemas.py           # Pydantic validation models
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.yaml        # Configuration (api_key, model path, CORS, etc.)
â”œâ”€â”€ models/
â”‚   â””â”€â”€ iris_logreg.joblib   # Trained scikit-learn Logistic Regression model
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ train_model.ipynb    # Jupyter notebook to train and save the model
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ test_health.py
â”‚   â”œâ”€â”€ test_predict.py
â”‚   â””â”€â”€ test_batch.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md

## ğŸš€ Features Implemented

- [x] Load pre-trained model at startup via configuration  
- [x] `/health` (GET), `/predict` (POST), `/batch_predict` (POST list) endpoints  
- [x] Pydantic-based request validation with clear 400 errors  
- [x] Global exception handling returning JSON error responses  
- [x] API key authentication and secure CORS configuration  
- [x] Structured JSON logging for all requests/responses  
- [x] Flask test client coverage for happy and edge paths  
- [x] Dockerfile for containerized deployment  


## âš™ï¸ Setup Instructions
### 1. Create and activate environment
conda create -p flaskml python=3.11 -y
conda activate ./flaskml

### 2. Install dependencies
pip install -r requirements.txt

### 3. Train the model
Open and run the notebook:
notebooks/train_model.ipynb

This will generate the file:
models/iris_logreg.joblib

### 4. Run the API
python -m app

You should see:
 * Running on http://127.0.0.1:5000/

## ğŸ”‘ API Authentication
All endpoints (except `/health`) require an API key.
The key is defined in `config/settings.yaml`:
api_key: CHANGE_ME

Pass it in the request header:
x-api-key: CHANGE_ME

## ğŸ§© Endpoints

### 1. GET `/health`
Check app and model status
curl http://localhost:5000/health

Response:
{
  "status": "ok",
  "model": "logreg-iris",
  "model_version": "1.0"
}

### 2. POST `/predict`
Predict class for a single sample
curl -X POST http://localhost:5000/predict \
  -H "Content-Type: application/json" \
  -H "x-api-key: CHANGE_ME" \
  -d "{\"id\":\"r1\", \"features\":[5.1,3.5,1.4,0.2]}"

Response:
{
  "id": "r1",
  "label": "setosa",
  "probability": 0.9821,
  "model_version": "1.0"
}

### 3. POST `/batch_predict`
Predict for multiple samples
curl -X POST http://localhost:5000/batch_predict \
  -H "Content-Type: application/json" \
  -H "x-api-key: CHANGE_ME" \
  -d "{\"items\": [
        {\"id\": \"r1\", \"features\": [5.1,3.5,1.4,0.2]},
        {\"id\": \"r2\", \"features\": [6.2,2.8,4.8,1.8]}
      ]}"

Response:
{
  "results": [
    {"id": "r1", "label": "setosa", "probability": 0.9821, "model_version": "1.0"},
    {"id": "r2", "label": "virginica", "probability": 0.8743, "model_version": "1.0"}
  ]
}

## ğŸ§  Model Details
Dataset: Iris
Algorithm: Logistic Regression (multi-class)
Accuracy: ~96% on test data
Features: sepal length, sepal width, petal length, petal width
Classes: setosa, versicolor, virginica
Saved model: models/iris_logreg.joblib

## ğŸ§ª Run Tests
pytest -q

Expected output:
.....                                                           [100%]
5 passed in 1.3s

## ğŸ³ Docker Instructions
Build image:
docker build -t flask-ml-api .

Run container:
docker run -p 5000:5000 flask-ml-api

Access the app at:
http://localhost:5000/health

## ğŸ“¸ Suggested Demo Screenshots
1. `/health` output in terminal
2. `/predict` output (JSON response)
3. `/batch_predict` output
4. `pytest` output showing â€œ5 passedâ€

Include these in your slides or assignment submission.

## ğŸ§¾ Summary
This project demonstrates a complete ML model deployment workflow:
- Model training
- API development and validation
- Authentication and error handling
- Testing and Dockerization

Itâ€™s simple, modular, and production-style â€” suitable for an AI/ML intern assignment or as a base for larger ML services.

Author: Mukunda (AI & Data Science Student)
Tools Used: Python, Flask, scikit-learn, Pydantic, pytest, Docker
Environment: Python 3.11 (conda-based)
